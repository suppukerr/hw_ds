{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Введение в Машинное Обучение. ","metadata":{"id":"Wj25Xo8RSMgG"}},{"cell_type":"markdown","source":"## Практическое домашнее задание 2","metadata":{"id":"Urzq8ZMwSOmZ"}},{"cell_type":"markdown","source":"### Общая информация","metadata":{"id":"IFccydP1SPMx"}},{"cell_type":"markdown","source":"\n\n```\n# Выбран кодовый формат\n```\n\nДата выдачи: 08.06.2022\n\nДедлайн: 15.06.2022 23:59","metadata":{"id":"J7p2ZSLPSPSl"}},{"cell_type":"markdown","source":"### О задании\n\nЗадание состоит из 4 частей. В рамках данной работы вам нужно будет работать с текстовыми объявлениями с платформы Avito. \n\n[ссылочка на связанный контест с дз](https://www.kaggle.com/competitions/hse-intro-ds-2022-hw2/overview)\n\nТеперь вам придется более плотнее поработать с текстом. А именно: построить некоторые статистики на имеющихся текстовых данных. Заняться лемматизацией/стэммингом, поработать с фильтрацией текстовых данных.\n\nДанные для домашнего задания расположены там же в контесте. Он также имеет четкий дедлайн, до которого вы можете заслать туда посылки (дедлайн в нем стоит чуть позже дедлайна дз, на всякий случай).\n\nДля доступа к данным и лидерборду в контесте необходимо принять его правила. С ними все просто.","metadata":{"id":"-fh4q9p_SPVI"}},{"cell_type":"markdown","source":"### Формат сдачи\n\nОформленный юпитер ноутбук отправляете на почту: `Anshtein99@mail.ru`\n\nВ теме письма указать (x - номер группы): 2022_fikl_ml_dz2_Surname_Name\n\nФайл должен именоваться так: dz2_Surname_Name.ipynb (и да, здесь нужны именно ваши фамилия и имя)","metadata":{"id":"i12pGUp1SPXz"}},{"cell_type":"markdown","source":"### Оценивание и штрафы\n\nКаждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n\nЗадание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).","metadata":{"id":"2FwsSr9GVdx6"}},{"cell_type":"markdown","source":"**Дисклеймер!!!!** не удаляйте, пожалуйста, поле id из ваших данных, ни из тестовых, ни из учебных. Иначе вашы шансы сдать свои сабмишшины в систему будут стремиться к 0","metadata":{"id":"YBdxqV4-Vd0w"}},{"cell_type":"markdown","source":"","metadata":{"id":"w5sUS6_2VmB7"}},{"cell_type":"markdown","source":"","metadata":{"id":"rSCompMXVmEO"}},{"cell_type":"markdown","source":"UPD. В рамках этого задания данные имеют достаточно внушительный объем, поэтому рекомендуем вам выполнять данную работу в юпитер коллабе.\n\nТакже важно!!!: промежуточные вычисления вы можете сохранять на жесткий диск коллаба, т.к. в какой-то момент все необходимые матрицы могут не влезть к вам в оперативную память.\nТакже стоит сохранять веса некоторых посчитанных моделей (на всякий случай)\nКак это делать описано [тут](https://scikit-learn.org/stable/model_persistence.html)","metadata":{"id":"cO0Yuza2VmG0"}},{"cell_type":"markdown","source":"### 0. Закачка данных\n\nВ рамках этой дз настоятельно рекомендуем загрузить `train.csv` и `test.csv` предварительно на ваш гугл диск. Это достаточно сильно облегчит вам жизнь при подзагрузке данных сюда в коллаб. Сами датасеты вы сможете подтянуть через код ниже:","metadata":{"id":"sg6tH-yAWYLO"}},{"cell_type":"code","source":"from tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:19:34.851943Z","iopub.execute_input":"2022-06-16T20:19:34.852622Z","iopub.status.idle":"2022-06-16T20:19:35.991288Z","shell.execute_reply.started":"2022-06-16T20:19:34.852492Z","shell.execute_reply":"2022-06-16T20:19:35.989873Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import os\n# os.getcwd()","metadata":{"id":"EPS6SQtKEzzE","outputId":"97bd5535-5a44-4739-a948-69858202589c","execution":{"iopub.status.busy":"2022-06-14T16:49:41.489053Z","iopub.execute_input":"2022-06-14T16:49:41.489372Z","iopub.status.idle":"2022-06-14T16:49:41.493857Z","shell.execute_reply.started":"2022-06-14T16:49:41.489344Z","shell.execute_reply":"2022-06-14T16:49:41.492976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nTrain = pd.read_csv('../input/train-hw2/train.csv')","metadata":{"id":"YzwSNZvcXGDk","execution":{"iopub.status.busy":"2022-06-16T20:19:35.993482Z","iopub.execute_input":"2022-06-16T20:19:35.993959Z","iopub.status.idle":"2022-06-16T20:20:45.210204Z","shell.execute_reply.started":"2022-06-16T20:19:35.993916Z","shell.execute_reply":"2022-06-16T20:20:45.205852Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Как вы можете заметить, наш датасет для обучения весит достаточно много, а в ресурсах на коллабе мы ограничены, поэтому в рамках учебного ресерча мы перейдем к исследованию конкретной части семпла нашего трейна:","metadata":{"id":"qTQZngXqXybQ"}},{"cell_type":"code","source":"## ну и зафиксируем рандом на всякий случай)\nTrain = Train.sample(1000000, random_state=1337, replace=True)\n## так жизнь пойдет легче","metadata":{"id":"Z1NvTG7_XX-E","execution":{"iopub.status.busy":"2022-06-14T16:50:44.420294Z","iopub.execute_input":"2022-06-14T16:50:44.421219Z","iopub.status.idle":"2022-06-14T16:50:45.655115Z","shell.execute_reply.started":"2022-06-14T16:50:44.421153Z","shell.execute_reply":"2022-06-14T16:50:45.65422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T16:50:45.65827Z","iopub.execute_input":"2022-06-14T16:50:45.658761Z","iopub.status.idle":"2022-06-14T16:50:45.722655Z","shell.execute_reply.started":"2022-06-14T16:50:45.658715Z","shell.execute_reply":"2022-06-14T16:50:45.721635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Копаемся в полученных данных","metadata":{"id":"3MdK_UHiZxDN"}},{"cell_type":"markdown","source":"Посмотрим на несколько на несколько строк нашего датасета. Первое, что стоит поисследовать, это наши метки, которые удобным образом представлены в текстовом формате. Поэтому...\n\n**Заадние 1.** (1 балл). Постройте график распределения имеющихся классов. Хотелось бы увидть какую-нибудь гистограмму, где визуально видно топ-5 самых популярных и топ-5 самых непопулярных классов. Что это за категории?\nВыведите из нашего трейна по паре объявлений из этих категорий. Можно ли заметить между ними (объявлениями 1 класса) какое-то сходство уже на данном этапе?","metadata":{"id":"Y0JXUoeuaWe_"}},{"cell_type":"code","source":"df1 = Train.groupby('Category_name')['title'].nunique()","metadata":{"id":"p4ufe62RXX73","execution":{"iopub.status.busy":"2022-06-14T16:50:45.726282Z","iopub.execute_input":"2022-06-14T16:50:45.726644Z","iopub.status.idle":"2022-06-14T16:50:46.976659Z","shell.execute_reply.started":"2022-06-14T16:50:45.726603Z","shell.execute_reply":"2022-06-14T16:50:46.975632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Топ-5 самых популярных категорий классов, которые мы предварительно рассматриваем просто про отсортированным категориям","metadata":{}},{"cell_type":"code","source":"df1.sort_values(ascending=False)[0:5]","metadata":{"execution":{"iopub.status.busy":"2022-06-14T16:50:46.978087Z","iopub.execute_input":"2022-06-14T16:50:46.978508Z","iopub.status.idle":"2022-06-14T16:50:46.987291Z","shell.execute_reply.started":"2022-06-14T16:50:46.978467Z","shell.execute_reply":"2022-06-14T16:50:46.986352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.sort_values(ascending=False)[0:5].plot(kind='bar', color = 'y')\nplt.ylabel('Количество')\nplt.xlabel('Категории')\nplt.title('Диаграмма')","metadata":{"execution":{"iopub.status.busy":"2022-06-14T16:50:46.988678Z","iopub.execute_input":"2022-06-14T16:50:46.989585Z","iopub.status.idle":"2022-06-14T16:50:47.271249Z","shell.execute_reply.started":"2022-06-14T16:50:46.989547Z","shell.execute_reply":"2022-06-14T16:50:47.269261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Топ-5 самых непопулярных категорий классов, которые мы предварительно рассматриваем просто про отсортированным категориям","metadata":{}},{"cell_type":"code","source":"df1.sort_values(ascending=True)[0:5]","metadata":{"execution":{"iopub.status.busy":"2022-06-14T16:50:47.272478Z","iopub.execute_input":"2022-06-14T16:50:47.272845Z","iopub.status.idle":"2022-06-14T16:50:47.284577Z","shell.execute_reply.started":"2022-06-14T16:50:47.272813Z","shell.execute_reply":"2022-06-14T16:50:47.283508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.sort_values(ascending=True)[0:5].plot(kind='bar', color = 'g')\nplt.ylabel('Количество')\nplt.xlabel('Категории')\nplt.title('Диаграмма')","metadata":{"execution":{"iopub.status.busy":"2022-06-14T16:50:47.287877Z","iopub.execute_input":"2022-06-14T16:50:47.288334Z","iopub.status.idle":"2022-06-14T16:50:47.493696Z","shell.execute_reply.started":"2022-06-14T16:50:47.2883Z","shell.execute_reply":"2022-06-14T16:50:47.493041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Задание 2.** (1 балл). Попробуем также исследовать некоторое текстовое наполнение наших объявлений. Посчитайте топ-10 самых часто встречаемых слов в объявлениях (т.е. во всем 1млн строк) вне зависимости от их формы. Также рассмотрите топ-10 самых редких слов.\n\nНа данном этапе, до обработки текста, можно условиться, что за слово в объявлении мы будет считать набор символов, отделенный от других наборов символов двумя пробелами. Сделайте некоторые выводы по полученному топу и антитопу слов.","metadata":{"id":"apmYAgP8b8IP"}},{"cell_type":"code","source":"from collections import Counter\ncoun = Counter(''.join(Train['description']).split())","metadata":{"execution":{"iopub.status.busy":"2022-06-14T16:50:47.494855Z","iopub.execute_input":"2022-06-14T16:50:47.495512Z","iopub.status.idle":"2022-06-14T16:51:17.779995Z","shell.execute_reply.started":"2022-06-14T16:50:47.49548Z","shell.execute_reply":"2022-06-14T16:51:17.779152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = coun.most_common(10)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T16:51:17.781475Z","iopub.execute_input":"2022-06-14T16:51:17.78252Z","iopub.status.idle":"2022-06-14T16:51:18.560631Z","shell.execute_reply.started":"2022-06-14T16:51:17.782471Z","shell.execute_reply":"2022-06-14T16:51:18.559597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"execution":{"iopub.status.busy":"2022-06-14T16:51:18.562019Z","iopub.execute_input":"2022-06-14T16:51:18.562338Z","iopub.status.idle":"2022-06-14T16:51:18.570165Z","shell.execute_reply.started":"2022-06-14T16:51:18.56231Z","shell.execute_reply":"2022-06-14T16:51:18.569047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В топе оказываются в основном служебные слова -- предлоги, частицы, кроме того, сюда попадает пунктуационные знаки. То есть подобный топ в первую очередь указывает на необходимость избавиться от символов в списке.","metadata":{}},{"cell_type":"code","source":"plt.bar(range(len(x)), [value[1] for value in x], color = 'c')\nplt.xticks(range(len(x)), [value[0] for value in x])\nplt.ylabel('Количество, млн')\nplt.xlabel('\"Слова\"')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T16:51:18.571784Z","iopub.execute_input":"2022-06-14T16:51:18.572374Z","iopub.status.idle":"2022-06-14T16:51:18.816891Z","shell.execute_reply.started":"2022-06-14T16:51:18.572325Z","shell.execute_reply":"2022-06-14T16:51:18.815884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = coun.most_common()[:-10-1:-1]","metadata":{"execution":{"iopub.status.busy":"2022-06-14T16:51:18.818241Z","iopub.execute_input":"2022-06-14T16:51:18.818576Z","iopub.status.idle":"2022-06-14T16:51:20.055576Z","shell.execute_reply.started":"2022-06-14T16:51:18.818545Z","shell.execute_reply":"2022-06-14T16:51:20.054381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В антитопе оказывается какая-то несуразица(например, места, где опущен пробел), тоже придётся думать как от этого почистить тексты.","metadata":{}},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2022-06-14T16:51:20.057051Z","iopub.execute_input":"2022-06-14T16:51:20.057496Z","iopub.status.idle":"2022-06-14T16:51:20.070355Z","shell.execute_reply.started":"2022-06-14T16:51:20.057463Z","shell.execute_reply":"2022-06-14T16:51:20.069382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train.isnull().sum()","metadata":{"id":"-36HSBAqf6f6","execution":{"iopub.status.busy":"2022-06-14T16:51:20.071304Z","iopub.execute_input":"2022-06-14T16:51:20.071714Z","iopub.status.idle":"2022-06-14T16:51:20.680063Z","shell.execute_reply.started":"2022-06-14T16:51:20.071671Z","shell.execute_reply":"2022-06-14T16:51:20.679153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Видно, что есть объекты с пропуском в текстовом поле `description`. Заменим пропуски на пустую строку","metadata":{"id":"v5sF9u9rf7Dj"}},{"cell_type":"code","source":"Train.fillna('', inplace=True)","metadata":{"id":"pHvLNyLlf9XK","execution":{"iopub.status.busy":"2022-06-14T16:51:20.68154Z","iopub.execute_input":"2022-06-14T16:51:20.681911Z","iopub.status.idle":"2022-06-14T16:51:21.287117Z","shell.execute_reply.started":"2022-06-14T16:51:20.68188Z","shell.execute_reply":"2022-06-14T16:51:21.28625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для простоты конкатенируем строки из полей `title` и `description`","metadata":{"id":"UrYtg4FRgDGG"}},{"cell_type":"code","source":"Train['title&description'] = Train['title'].str[:] + ' ' + Train['description'].str[:]","metadata":{"id":"fCGX_2JVf9ts","execution":{"iopub.status.busy":"2022-06-14T16:51:21.28827Z","iopub.execute_input":"2022-06-14T16:51:21.288584Z","iopub.status.idle":"2022-06-14T16:51:24.708008Z","shell.execute_reply.started":"2022-06-14T16:51:21.288556Z","shell.execute_reply":"2022-06-14T16:51:24.707053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Разделим выборку ```Train``` на обучающую и тестовую","metadata":{"id":"mqZ60pVbgN4f"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(Train[['title&description']], Train['Category'], random_state=1337, test_size=100000)\n\ndel Train ## дальше в качестве данных для обучения используем X_train","metadata":{"id":"ZUSnCoTqgNmZ","execution":{"iopub.status.busy":"2022-06-14T16:51:24.709478Z","iopub.execute_input":"2022-06-14T16:51:24.709936Z","iopub.status.idle":"2022-06-14T16:51:25.721746Z","shell.execute_reply.started":"2022-06-14T16:51:24.709891Z","shell.execute_reply":"2022-06-14T16:51:25.719993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Обработка текста\n\nКак вы могли заметить в рамках предыдущих пунктов, наши объявления несут в себе некоторый текстовый \"мусор\". Различные местоимения, междометия, или вообще набор \"\\n\" и \"\\t\". Так что звучит довольно логично следующая мысль: давайте мы избавимся от этого мусора в тексте и проведем некоторую фильтрацию данных.\n\nТакже в купе с этим на ум приходит информация о том, что в наших объявлениях одни и те же слова могут быть записаны в различной языковой форме, использовать различные падежи. Поэтому что?\nДа, лемматезация. Благо, мы живем с вами в современном мире, и люди для этой задачи написали уже несколько фреймворков, которые нам с вами смогут помочь в этой задаче, в этой дз я рекомендую использовать pymorphy2.\n\nСледующая мысль, которая может прийти на ум в рамках обработки текстовых данных - это стоп слова. Их в наших объявлениях достаточно много (ведь их писали люди). Поэтому их также стоит отфильтровать.\n\nИсходя из этих пунктов, след задание можно описать так:\n\n**Задание 3.** (2 балла). Реализуйте функцию, которая принимает на вход строку, набор стоп слов и морфо-анализатор, и на выходе выдает набор слов (лемм), отчищенных от пунктуационных, разделяющих символов и стоп слов.\n\nНекоторый её возможный шаблон представлен ниже:","metadata":{"id":"wMatYR6wZmGE"}},{"cell_type":"markdown","source":"Подробнее про использование pymorphy смотрите [тут](https://pymorphy2.readthedocs.io/en/0.6/user/guide.html)","metadata":{"id":"rWYw4tKwjKkb"}},{"cell_type":"code","source":"## блок с подтягиванием библиотеки для лемматизации\n!pip install pymorphy2\n!pip install pymorphy2-dicts\n!pip install 'DAWG-Python >= 0.7'\n","metadata":{"id":"m59j7RTnjJQm","execution":{"iopub.status.busy":"2022-06-14T16:51:25.723516Z","iopub.execute_input":"2022-06-14T16:51:25.72401Z","iopub.status.idle":"2022-06-14T16:52:03.52354Z","shell.execute_reply.started":"2022-06-14T16:51:25.723968Z","shell.execute_reply":"2022-06-14T16:52:03.522183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pymorphy2\nmorph = pymorphy2.MorphAnalyzer()\n\n## словарь, он же файл, который мы выдали вам вместе с домашкой, вы также можете загрузить на диск, чтобы подгрузить его в коллаб\nstop_words = # Your code here (⊃｡•́‿•̀｡)⊃ пол чтению файла stop_word_ru и получения листа из нужных слов:","metadata":{"id":"Gyv0jLYsZli5","execution":{"iopub.status.busy":"2022-06-14T16:52:03.525715Z","iopub.execute_input":"2022-06-14T16:52:03.526725Z","iopub.status.idle":"2022-06-14T16:52:03.533364Z","shell.execute_reply.started":"2022-06-14T16:52:03.526681Z","shell.execute_reply":"2022-06-14T16:52:03.532158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clear_and_morhp(text, stop_words, morph):\n  '''\n  text: string - строка с нашим текстом\n  stop_words - List с выданными вам стоп словами\n  morph - анализатор текста\\слов для получения лемм\n  так же не забудьте привести все слова к единому регистру\n  return List слов, преобразованных до лемм + убраны различные знаки + стоп слова\n  '''\n    text = text.replace(',', '')\n    text = text.replace('.', '')\n    text = text.replace('?', '')\n    text = text.replace(':', '')\n    text = text.replace(';', '')\n    text = text.replace('-', '')\n    text = text.replace('%', '')\n    text = text.replace('/', '')\n    text_without = [word for word in text.split(' ') if not word in stop_words]\n    text_norm = [morph.parse(word)[0].normal_form for word in text_without]\n\n    return text_norm\n\n  ## её использование к нашим данн в таком формате: X_train[['title&description']].apply(lambda x: clear_and_morhp(x, stop_words, morph))","metadata":{"id":"ElMYlku8Zlf8","execution":{"iopub.status.busy":"2022-06-14T16:52:03.534214Z","iopub.status.idle":"2022-06-14T16:52:03.534657Z","shell.execute_reply.started":"2022-06-14T16:52:03.534451Z","shell.execute_reply":"2022-06-14T16:52:03.534469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Если с реализацией данной функции возникнту проблемы - не стеняйтесь писать об этом в наш чат для получения помощи.\n\nТакже вы можете реализовать не все 3 составляющих очистки текста, а какую-то их часть, но это даст вам меньше баллов.\n\n\nПосле реализации данной функции мы можем применить её к нашим данным и получить более \"чистый\" набор слов.","metadata":{"id":"Pk6RtT3pj6Dx"}},{"cell_type":"code","source":"# Your code here (⊃｡•́‿•̀｡)⊃ для получения очищенных данных через вашу функцию","metadata":{"id":"DxZL57hmtSSD","execution":{"iopub.status.busy":"2022-06-14T16:52:03.536076Z","iopub.status.idle":"2022-06-14T16:52:03.536454Z","shell.execute_reply.started":"2022-06-14T16:52:03.536287Z","shell.execute_reply":"2022-06-14T16:52:03.536304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Построение простых эмбеддингов и работа с моделями\n\nСейчас вы визуально можете сравнить по определенному набору строк (допустим вызвав `.head(15)`) как изменились наши текстовые данные после предобработки. Так что мы можем с уверенностью сказать, что некоторое визуальное преобразование появилось. Но а выиграли ли мы с точки зрения достижения результата в рамках нашей задачи. Разберемся в этой части домашки.","metadata":{"id":"KUAEte8lkYR4"}},{"cell_type":"markdown","source":"**Задание 3.1** (0.5 балла) В рамках этого пункта нам стоит получить некоторый `бейзлайн`, с которым мы будем сравнивать остальные наши модели. Для этого вернемся к трейну X_train, в котором все еще находился мусор, слова всех форм и стоп-слова. Воспользуемся построением Tf-Idf матрицы от этих данных и также используем SGDClassifier в качестве достаточно простой модели.\n\nНу и в качестве метрики мы будем использовать accuracy (для подсчета этой метрики используем имеющийся у нас уже X_test), т.к. у нас все же многоклассовая классификация. Результат этой модели мы будем сравнивать с другими по ходу этого задания.","metadata":{"id":"n6npoO_ls5eL"}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Your code here (⊃｡•́‿•̀｡)⊃","metadata":{"id":"vm2GFUI3iELP","execution":{"iopub.status.busy":"2022-06-14T16:52:03.538095Z","iopub.status.idle":"2022-06-14T16:52:03.538475Z","shell.execute_reply.started":"2022-06-14T16:52:03.538307Z","shell.execute_reply":"2022-06-14T16:52:03.538324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Задание 3.2** (0.5 балла) У метода TfidfVectorizer есть набор своих параметров. В рамках этого задания мы предлагаем вам поизучать возможные гиперпараметры этого метода и подобрать такие значения, которые вам позволят получить более лучший результат на непредобработанном X_train на той же простой модели SGDClassifier. Как вариант вы можете рассмореть н-граммы большей длины или поставить ограничение сверху на кол-во получаемых токенов в данном методе. 3-4 экспериментов с различными значениями гиперпараметорв будет достаточно, чтобы можно было сделать возможные выводы о значениях, которые подходят в рамках нашей задачи.","metadata":{"id":"dFkiHFNptsOy"}},{"cell_type":"code","source":"# Your lots of code here (⊃｡•́‿•̀｡)⊃","metadata":{"id":"HX62vqpGiEJD","execution":{"iopub.status.busy":"2022-06-14T16:52:03.540057Z","iopub.status.idle":"2022-06-14T16:52:03.540459Z","shell.execute_reply.started":"2022-06-14T16:52:03.540269Z","shell.execute_reply":"2022-06-14T16:52:03.540287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Задание 3.3** (3 балла) Теперь подключим рассмотрению такой подход к агрегации фичей как Bag of words. В каком-то смысле, математически он слабее tf-idf подхода, но для этого мы и столкнем их в рамках нашего задания, чтобы посмотреть на результат.\n\nВ рамках этой части домашки предобработайте **уже очищенные** данные через tf-idf и bag of words подходы. И на полученных наборах фичей обучите **SGDClassifier**, какой-нибудь градиентный бустинг (к примеру XGBoost) и удобное для вас дерево решений (из того же sklearn). \n\n**Минимально** у вас должно получиться **6 экспериментов**, между которыми вы сравниваете полученные accuracy. Также для устойчивого обучения стоит поиграться с параметрами двух выбранных моделей и подходов агрегации, или же провести дополнительные эксперименты, чтобы сделать выводы, как изменение параметров моделей обучения от дефолтных влияет на наши итоговые результаты.\n\nПосле проведенных экспериментов стоит изложить некоторые выводы о полученных результатах. Как повлияли разные подходы tf-id и bag of words на обучение одной и той же модели, как сопоставимы результаты с этими подходами на разных моделях.","metadata":{"id":"v5dZYXm-vkFP"}},{"cell_type":"code","source":"# Your 4 experiments here (⊃｡•́‿•̀｡)⊃","metadata":{"id":"ec0HMM3-iEGW","execution":{"iopub.status.busy":"2022-06-14T16:52:03.54183Z","iopub.status.idle":"2022-06-14T16:52:03.542222Z","shell.execute_reply.started":"2022-06-14T16:52:03.542029Z","shell.execute_reply":"2022-06-14T16:52:03.542046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. В погоне за кагглом (снова)\n\n**Задание 4.** (1 балл) Да, вам снова нужно попробовать собрать сабмит для нашей тестирующей системе на каггле, для этого:\nВы выбираете одну из рассмотренных пар: подхода к агрегации фичей и саму модель (или же берете вообще какой-нибудь LinearSVC, мы не запрещаем).\nДелаете такую же предобработку данных к тесту (очистка, агрегация фичей), и по выбранной вами модели строите предикт для тестовых данных. Сохранить его также стоит сразу по пути на диск: `/content/drive/MyDrive/ds_intro_hw2/submit.csv`, чтобы его было оттуда файликом проще забрать.","metadata":{"id":"rmwPRMCsvk3X"}},{"cell_type":"code","source":"Test = pd.read_csv('/content/drive/MyDrive/то_же_самое_с_файлом_для_тестирования.csv')\n\n# Your cleaning text and predict here (⊃｡•́‿•̀｡)⊃","metadata":{"id":"BpUK0nMPXGA2","execution":{"iopub.status.busy":"2022-06-14T16:52:03.543396Z","iopub.status.idle":"2022-06-14T16:52:03.543834Z","shell.execute_reply.started":"2022-06-14T16:52:03.543617Z","shell.execute_reply":"2022-06-14T16:52:03.543663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Рисерч\n\n**Задание 5.** (1 балл) В рамках этого пункта мы предлагаем вам еще поработать над данной задачей в другом подходе. В рамках задания 3 мы обучили некоторый ансамбл моделей. А что, если они будут работать над нашей задачей вместе? Да, фактически в этой задаче может помочь некотрое ансамблирование моделей.\n\nДля его более честной и усточивой работы, к имеющимся обучающим данным вы можете применить бустреп к каждой из n-моделей (сколько вы выберете - дело ваше, но желательно не меньше 3), чтобы ей на вход поступили разные подмножества данных.\n\nИли же вы можете поискать другие полезные закономерности в имеющихся данных, которые помогут улучшить нашу метрику качества по этой задаче. В этом плане мы вас не ограничиваем.\n\nНо если все же в голову ничего не приходит, предлагаем рассмотреть ансамблирование нескольких моделей.\n\nВ рамках ограничения оперативной памяти, вы можете их обучить по отдельности, после сохранить черзе `pickle` и после подгрузить их для некторого ансамблирования. Итоговый класс вы можете выбирать через выбор большинства, или же предложить свою эвристику.","metadata":{"id":"6I6sGmEr2eG8"}},{"cell_type":"code","source":" # Your research here (⊃｡•́‿•̀｡)⊃","metadata":{"id":"h1-pSxc61uTS","execution":{"iopub.status.busy":"2022-06-14T16:52:03.54581Z","iopub.status.idle":"2022-06-14T16:52:03.546173Z","shell.execute_reply.started":"2022-06-14T16:52:03.546002Z","shell.execute_reply":"2022-06-14T16:52:03.546019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Дополнительное задание\n\n**Задание 6.** (+1 доп балл) Попробуйте использовать дополнительные подходы генерации признаков на текстовых даннных (fasttext, w2v и др) и для дальнейшего обучения моделей. Повысилось ли качество модели? Сделайте выводы.\n","metadata":{"id":"0qKqI7n0h6u9"}},{"cell_type":"code","source":" # Your research here (⊃｡•́‿•̀｡)⊃","metadata":{"id":"GxQe1qSkioJH","execution":{"iopub.status.busy":"2022-06-14T16:52:03.546944Z","iopub.status.idle":"2022-06-14T16:52:03.547325Z","shell.execute_reply.started":"2022-06-14T16:52:03.547136Z","shell.execute_reply":"2022-06-14T16:52:03.547164Z"},"trusted":true},"execution_count":null,"outputs":[]}]}